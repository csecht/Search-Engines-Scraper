<!DOCTYPE html>
<meta charset="utf-8"><!--markdown .md to HTML conversion courtesy of https://markdowntohtml.com/ -->
<h1 id="search-engines-scraper-cse">Search Aggregator</h1>
<p>Aggregates results from several search engines with output to Terminal and text file. This is a fork of Search Engines Scraper by tasos_py, but is run from the <code>aggregate_search.py</code> Python script.</p>
<h2 id="supported-search-engines">Supported search engines</h2>
<ul><li><em><a href="https://duckduckgo.com">Duckduckgo</a></em>
<li><em><a href="https://www.startpage.com">Startpage</a></em>
<li><em><a href="https://www.mojeek.com">Mojeek</a></em>
    <li><em><a href="https://metager.org">MetaGer</a></em></ul>
<h2 id="features">Features</h2>
<ul>
<li>Uses search engines that are focused on user privacy.</li>
<li>Non-redundant results (URL, page title, page detail) are printed to the Terminal/console with easy-to-read colors and to an automatically named text file.</li>
<li>A random user agent is assigned from an appropriate set of options for each engine.</li>
</ul>
<h2 id="requirements">Requirements</h2>
<p><em>Python 3</em> with
<em><a href="http://docs.python-requests.org/en/master/">Requests</a></em> and
<em><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a></em> </p>
<p>Developed in Python 3.8-3.9</p>
<h2 id="installation">Installation</h2>
<p>Download the .zip code archive, extract the .zip file, open Terminal/Command Prompt in the search-aggregator-main folder, run the setup file:</p>
<p><code>$ python3 setup.py install</code></p>
<p>Done!</p>
<h2 id="usage">Usage</h2>
From within the search-aggregator-main folder, execute <code>aggregate_search.py</code> from Terminal/Command Prompt:
<ul><li>Linux/MacOS: <code>python3 aggregate_search.py</code> or <code>./aggregate_search.py</code>
<li>Windows: <code>python3 aggregate_search.py</code> or <code>python aggregate_search.py</code> or <code>py aggregate_search.py</code>, depending on your system environment.
</ul>
Example output:
<pre><code>    Enter search term: gov forest policies

    User agents assigned for this search:
    MegaGer:   Firefox/74.0
    DuckDuckGo:aggregate_search/0.4 Repo: https://github.com/csecht/search-aggregator
    Startpage: Firefox/82.0
    Mojeek:    b'Opera/8.10 (Windows NT 5.1; U; en)'

    Searching Metager
    Keeping the first 30 results from MetaGer (MG)
    Searching Duckduckgo
    Keeping the first 20 results from DuckDuckGo (DDG)
    Searching Startpage
    Keeping the first 20 results from Startpage (SP)
    Searching Mojeek
    Keeping the first 20 results from Mojeek (Moj)
    Kept 90 total results.

    There are 74 unique results.
    24 unique results retained from (MG)
    14 unique results retained from (DDG)
    16 unique results retained from (SP)
    20 unique results retained from (Moj)

    https://www.fs.usda.gov/about-agency/regulations-policies
    (SP) Regulations & Policies | US Forest Service
    Federal agencies operate under the U.S. Code and the Code of Federal Regulations. These laws help form our directives and policies on how we manage national ...

    https://www.fs.usda.gov/science-technology/forest-products-modernization/policy-updates
    (MG) Policy Updates | US Forest Service - USDA
    Timber sales production in the Chattahoochee National Forest, GA. (Forest Service photo by Cecilio Ricardo). The USDA Forest Service recently issued…

    https://portal.ct.gov/DEEP/Forestry/Forest-Policy-and-Planning
    (Moj) CT Forest Policy and Planning
    Some of the features on CT.gov will not function properly with out javascript enabled. ... Get the latest updates on COVID-19 at ct.gov/coronavirus .

    https://kingcounty.gov/services/environment/water-and-land/forestry/forest-policy.aspx
    (DDG) Forest policy and planning - King County
    The Forestry Program is guided by the King County Comprehensive Plan, which establishes policies on the management of rural land and the uses that are suitable to the rural area. The Comprehensive Plan directs that strategies be developed to maintain forest cover and support the practice of sustainable forestry.
</code></pre><p>...and the remaining results. All results would be printed to Terminal and written to a file automatically titled: Results_gov+forest+policies.txt</p>
<p>Example of color-enhanced Terminal output:
<img src="images/scrnshot_output.png" alt="color_output"></p>
<p>ARGUMENTS: --help, --info, --use, or --x.</p>
<ul><li>The command <code>aggregate_search.py --use</code> provides examples of search term syntax, then exits.</li>
<li>The command <code>aggregate_search.py --x 2</code> doubles the number of results returned; <code>--x 3</code> triples results, etc., up to <code>--x 5</code>. Without an --x argument, ~60 -- 80 total unique results are returned.</li>
</ul>
<h3 id="single-engine-search">Single engine search</h3>
<p>The original command line client from Search-Engines-Scraper, <code>search_engines_cli.py</code> can be used for customized searches. For example,</p>
<pre><code>python3 search_engines_cli<span class="hljs-selector-class">.py</span> -<span class="hljs-selector-tag">q</span> forestry -<span class="hljs-selector-tag">p</span> <span class="hljs-number">4</span> -e mojeek
</code></pre><p>will return four pages of url results for the query &#39;forestry&#39; from the Mojeek engine. To see additional search and output options, use the help command,</p>
<pre><code>python3 search_engines_cli<span class="hljs-selector-class">.py</span> -h
</code></pre>